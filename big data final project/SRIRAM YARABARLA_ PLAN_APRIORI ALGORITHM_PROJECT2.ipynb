{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#using pandas\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#os.chdir('C:\\Users\\srira\\Desktop')\n",
    "#os.chdir('C:\\Users\\caccess\\Desktop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!type plan.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Request Type</td>\n",
       "      <td>Wireless Account Type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WIRELESS</td>\n",
       "      <td>IR - Individual Regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WIRELESS</td>\n",
       "      <td>IR - Individual Regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WIRELESS</td>\n",
       "      <td>IR - Individual Regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WIRELESS</td>\n",
       "      <td>IR - Individual Regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WIRELESS</td>\n",
       "      <td>IR - Individual Regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>WIRELESS</td>\n",
       "      <td>IR - Individual Regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>WIRELESS</td>\n",
       "      <td>IR - Individual Regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>WIRELESS</td>\n",
       "      <td>IR - Individual Regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WIRELESS</td>\n",
       "      <td>IR - Individual Regular</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0                        1\n",
       "0  Data Request Type    Wireless Account Type\n",
       "1           WIRELESS  IR - Individual Regular\n",
       "2           WIRELESS  IR - Individual Regular\n",
       "3           WIRELESS  IR - Individual Regular\n",
       "4           WIRELESS  IR - Individual Regular\n",
       "5           WIRELESS  IR - Individual Regular\n",
       "6           WIRELESS  IR - Individual Regular\n",
       "7           WIRELESS  IR - Individual Regular\n",
       "8           WIRELESS  IR - Individual Regular\n",
       "9           WIRELESS  IR - Individual Regular"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_table(\"plan.csv\", sep=',', header=None)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = genfromtxt('plan.csv',skip_header=1, delimiter=',', dtype=None,usecols=arange(0,2))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing ATT data sets with Apriori algorithm"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "I have taken everything form only one article[1] and I have mentioned it below."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Apriori uses a breadth-first search strategy to count the support of itemsets and uses a candidate generation function which exploits the downward closure property of support."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The Apriori algorithm principle says that if an itemset is frequent, then all of its subsets are frequent.this means that if {0,1} is frequent, then {0} and {1} have to be frequent.\n",
    "\n",
    "The rule turned around says that if an itemset is infrequent, then its supersets are also infrequent.\n",
    "\n",
    "We first need to find the frequent itemsets, and then we can find association rules."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Interesting relationships can take two forms: frequent item sets or association rules. \n",
    "Frequent item sets are a collection of items that frequently occur together. The second way to view interesting relationships is association rules. Association rules suggest that a strong relationship exists between two items.\n",
    "\n",
    "With the frequent item sets and association rules, retailers have a much better understanding of their customers. Another example is search terms from a search engine."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "General approach to the Apriori algorithm\n",
    "\n",
    "Collect: Any method.\n",
    "Prepare: Any data type will work as we’re storing sets.\n",
    "Analyze: Any method.\n",
    "Train: Use the Apriori algorithm to find frequent itemsets.\n",
    "Test: Doesn’t apply.\n",
    "Use: This will be used to find frequent itemsets and association rules between items."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The way to find frequent itemsets is the Apriori algorithm. The Apriori algorithm needs a minimum support level as an input and a data set. The algorithm will generate a list of all candidate itemsets with one item. The transaction data set will then be scanned to see which sets meet the minimum support level. Sets that don’t meet the minimum support level will get tossed out. The remaining sets will then be combined to make itemsets with two elements. Again, the transaction dataset will be scanned and itemsets not meeting the minimum support level will get tossed. This procedure will be repeated until all sets are tossed out."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "It creates C1 .C1 is a candidate itemset of size one. In the Apriori algorithm, we create C1, and then we’ll scan the dataset to see if these one itemsets meet our minimum support requirements. The itemsets that do meet our minimum requirements become L1. L1 then gets combined to become C2 and C2 will get filtered to become L2.\n",
    "\n",
    "Frozensets are sets that are frozen, which means they’re immutable; you can’t change them. You need to use the type frozenset instead of set because you’ll later use these sets as the key in a dictionary.\n",
    "\n",
    "You can’t create a set of just one integer in Python. It needs to be a list (try it out). That’s why you create a list of single-item lists. Finally, you sort the list and then map every item in the list to frozenset() and return this list of frozensets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createC1(dataSet):\n",
    "    C1 = []\n",
    "    for transaction in dataSet:\n",
    "        for item in transaction:\n",
    "            if not [item] in C1:\n",
    "                C1.append([item])\n",
    "                \n",
    "    C1.sort()\n",
    "    return list(map(frozenset, C1))#use frozen set so we\n",
    "                            #can use it as a key in a dict    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[frozenset({'CB-U-VERSE'}),\n",
       " frozenset({'CB-WIRELINE'}),\n",
       " frozenset({'IR - Individual Regular'}),\n",
       " frozenset({'Unified (Uverse + Wireless + DTV)'}),\n",
       " frozenset({'WIRELESS'})]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C1 = createC1(a)\n",
    "C1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This function takes three arguments: a dataset, Ck, a list of candidate sets, and minSupport, which is the minimum support you’re interested in. This is the function you’ll use to generate L1 from C1. Additionally, this function returns a dictionary with support values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scanD(D, Ck, minSupport):\n",
    "    ssCnt = {}\n",
    "    for tid in D:\n",
    "        for can in Ck:\n",
    "            if can.issubset(tid):\n",
    "                if not can in ssCnt: ssCnt[can]=1\n",
    "                else: ssCnt[can] += 1\n",
    "    numItems = float(len(D))\n",
    "    retList = []\n",
    "    supportData = {}\n",
    "    for key in ssCnt:\n",
    "        support = ssCnt[key]/numItems\n",
    "        if support >= minSupport:\n",
    "            retList.insert(0,key)\n",
    "        supportData[key] = support\n",
    "    return retList, supportData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D = list(map(set,a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[frozenset({'WIRELESS'}),\n",
       " frozenset({'CB-WIRELINE'}),\n",
       " frozenset({'IR - Individual Regular'}),\n",
       " frozenset({'Unified (Uverse + Wireless + DTV)'}),\n",
       " frozenset({'CB-U-VERSE'})]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L1,suppDat0 = scanD(D,C1,0.01)\n",
    "L1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The main function is apriori(); it calls aprioriGen() to create candidate itemsets: Ck.\n",
    "\n",
    "The function aprioriGen() will take a list of frequent itemsets, Lk, and the size of the itemsets, k, to produce Ck. For example, it will take the itemsets {0}, {1}, {2} and so on and produce {0,1} {0,2}, and {1,2}.\n",
    "\n",
    "The sets are combined using the set union, which is the | symbol in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def aprioriGen(Lk, k): #creates Ck\n",
    "    retList = []\n",
    "    lenLk = len(Lk)\n",
    "    for i in range(lenLk):\n",
    "        for j in range(i+1, lenLk): \n",
    "            L1 = list(Lk[i])[:k-2]; L2 = list(Lk[j])[:k-2]\n",
    "            L1.sort(); L2.sort()\n",
    "            if L1==L2: #if first k-2 elements are equal\n",
    "                retList.append(Lk[i] | Lk[j]) #set union\n",
    "    return retList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apriori(dataSet, minSupport = 0.1):\n",
    "    C1 = createC1(dataSet)\n",
    "    D = list(map(set, dataSet))\n",
    "    L1, supportData = scanD(D, C1, minSupport)\n",
    "    L = [L1]\n",
    "    k = 2\n",
    "    while (len(L[k-2]) > 0):\n",
    "        Ck = aprioriGen(L[k-2], k)\n",
    "        Lk, supK = scanD(D, Ck, minSupport)#scan DB to get Lk\n",
    "        supportData.update(supK)\n",
    "        L.append(Lk)\n",
    "        k += 1\n",
    "    return L, supportData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[frozenset({'WIRELESS'}), frozenset({'IR - Individual Regular'})],\n",
       " [frozenset({'IR - Individual Regular', 'WIRELESS'})],\n",
       " []]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L,suppData = apriori(a)\n",
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[frozenset({'WIRELESS'}), frozenset({'IR - Individual Regular'})]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[frozenset({'IR - Individual Regular', 'WIRELESS'})]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[frozenset({'IR - Individual Regular', 'WIRELESS'})]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aprioriGen(L[0],2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mining association rules from frequent item sets"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Association rules are usually required to satisfy a user-specified minimum support and a user-specified minimum confidence at the same time. Association rule generation is usually split up into two separate steps:\n",
    "\n",
    "A minimum support threshold is applied to find all frequent itemsets in a database.\n",
    "A minimum confidence constraint is applied to these frequent itemsets in order to form rules."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "To find association rules, we first start with a frequent itemset. We know this set of items is unique, but we want to see if there is anything else we can get out of these items. One item or one set of items can imply another item.\n",
    "\n",
    "generateRules(), is the main command, which calls the other two.\n",
    "\n",
    "The generateRules() function takes three inputs: a list of frequent itemsets, a dictionary of support data for those itemsets, and a minimum confidence threshold. It’s going to generate a list of rules with confidence values that we can sort through later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateRules(L, supportData, minConf=0.7):  #supportData is a dict coming from scanD\n",
    "    bigRuleList = []\n",
    "    for i in range(1, len(L)):#only get the sets with two or more items\n",
    "        for freqSet in L[i]:\n",
    "            H1 = [frozenset([item]) for item in freqSet]\n",
    "            if (i > 1):\n",
    "                rulesFromConseq(freqSet, H1, supportData, bigRuleList, minConf)\n",
    "            else:\n",
    "                calcConf(freqSet, H1, supportData, bigRuleList, minConf)\n",
    "    return bigRuleList   "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "calcConf() calculates the confidence of the rule and then find out the which rules meet the minimum confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcConf(freqSet, H, supportData, brl, minConf=0.7):\n",
    "    prunedH = [] #create new list to return\n",
    "    for conseq in H:\n",
    "        conf = supportData[freqSet]/supportData[freqSet-conseq] #calc confidence\n",
    "        if conf >= minConf: \n",
    "            print (freqSet-conseq,'-->',conseq,'conf:',conf)\n",
    "            brl.append((freqSet-conseq, conseq, conf))\n",
    "            prunedH.append(conseq)\n",
    "    return prunedH"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "rulesFromConseq() generates more association rules from our initial dataset. This takes a frequent itemset and H, which is a list of items that could be on the right-hand side of a rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rulesFromConseq(freqSet, H, supportData, brl, minConf=0.7):\n",
    "    m = len(H[0])\n",
    "    if (len(freqSet) > (m + 1)): #try further merging\n",
    "        Hmp1 = aprioriGen(H, m+1)#create Hm+1 new candidates\n",
    "        Hmp1 = calcConf(freqSet, Hmp1, supportData, brl, minConf)\n",
    "        if (len(Hmp1) > 1):    #need at least two sets to merge\n",
    "            rulesFromConseq(freqSet, Hmp1, supportData, brl, minConf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L,suppData= apriori(a,minSupport=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(frozenset(['IR - Individual Regular']), '-->', frozenset(['WIRELESS']), 'conf:', 0.8334489937543372)\n",
      "(frozenset(['WIRELESS']), '-->', frozenset(['IR - Individual Regular']), 'conf:', 1.0)\n"
     ]
    }
   ],
   "source": [
    "rules= generateRules(L,suppData, minConf=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have taken only a small part of the dataset for which I have analyzed the above results.\n",
    "\n",
    "The above rules confidently says that in NEWYORK city wirless is more and there is more confidence to install more wireless  over there and vice versa."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Citation:\n",
    "\n",
    "[1].vaish, piush. “Apriori Algorithm (Python 3.0).” A Data Analyst, Piush.vaish, 7 Aug. 2016, adataanalyst.com/machine-learning/apriori-algorithm-python-3-0/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
