{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#using pandas\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!type marketplan.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = genfromtxt('marketplan.csv',skip_header=1, delimiter=',', dtype=None,usecols=arange(0,2))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Newyork', 'WIRELESS'],\n",
       "       ['Newyork', 'WIRELESS'],\n",
       "       ['Newyork', 'WIRELESS'],\n",
       "       ..., \n",
       "       ['Missouri', 'CB-WIRELINE'],\n",
       "       ['Missouri', 'CB-WIRELINE'],\n",
       "       ['Missouri', 'CB-WIRELINE']],\n",
       "      dtype='|S33')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=np.array(x)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing ATT data sets with Frequent pattern growth algorithm"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "I have taken everything form only one article[1] and I have mentioned it below."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "FP-growth algorithm find frequent itemsets or pairs, sets of things that commonly occur together, by storing the dataset in a special structure called an FP-tree."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The FP-growth algorithm scans the dataset only twice. The basic approach to finding frequent itemsets using the FP-growth algorithm is as follows:\n",
    "1 Build the FP-tree.\n",
    "2 Mine frequent itemsets from the FP-tree.\n",
    "\n",
    "The FPtree is used to store the frequency of occurrence for sets of items. Sets are stored as paths\n",
    "\n",
    "in the tree. Sets with similar items will share part of the tree. Only when they differ will the tree split. A node identifies a single item from the set and the number of times it occurred in this sequence. A path will tell you how many times a sequence occurred. The links between similar items, known as node links, will be used to rapidly find the location of similar items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#variables:\n",
    "#name of the node, a count\n",
    "#nodelink used to link similar items\n",
    "#parent vaiable used to refer to the parent of the node in the tree\n",
    "#node contains an empty dictionary for the children in the node\n",
    "class treeNode:\n",
    "    def __init__(self, nameValue, numOccur, parentNode):\n",
    "        self.name = nameValue\n",
    "        self.count = numOccur\n",
    "        self.nodeLink = None\n",
    "        self.parent = parentNode      #needs to be updated\n",
    "        self.children = {} \n",
    "#increments the count variable with a given amount    \n",
    "    def inc(self, numOccur):\n",
    "        self.count += numOccur\n",
    "#display tree in text. Useful for debugging        \n",
    "    def disp(self, ind=1):\n",
    "        print ('  '*ind, self.name, ' ', self.count)\n",
    "        for child in self.children.values():\n",
    "            child.disp(ind+1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "createTree(), takes the dataset and the minimum support as arguments and builds the FP-tree. This makes two passes through the dataset. The first pass goes through everything in the dataset and counts the frequency of each term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createTree(dataSet, minSup=1): #create FP-tree from dataset but don't mine\n",
    "    headerTable = {}\n",
    "    #go over dataSet twice\n",
    "    for trans in dataSet:#first pass counts frequency of occurance\n",
    "        for item in trans:\n",
    "            headerTable[item] = headerTable.get(item, 0) + dataSet[trans]\n",
    "    for k in list(headerTable):  #remove items not meeting minSup\n",
    "        if headerTable[k] < minSup: \n",
    "            del(headerTable[k])\n",
    "    freqItemSet = set(headerTable.keys())\n",
    "    #print 'freqItemSet: ',freqItemSet\n",
    "    if len(freqItemSet) == 0: return None, None  #if no items meet min support -->get out\n",
    "    for k in headerTable:\n",
    "        headerTable[k] = [headerTable[k], None] #reformat headerTable to use Node link \n",
    "    #print 'headerTable: ',headerTable\n",
    "    retTree = treeNode('Null Set', 1, None) #create tree\n",
    "    for tranSet, count in dataSet.items():  #go through dataset 2nd time\n",
    "        localD = {}\n",
    "        for item in tranSet:  #put transaction items in order\n",
    "            if item in freqItemSet:\n",
    "                localD[item] = headerTable[item][0]\n",
    "        if len(localD) > 0:\n",
    "            orderedItems = [v[0] for v in sorted(localD.items(), key=lambda p: p[1], reverse=True)]\n",
    "            updateTree(orderedItems, retTree, headerTable, count)#populate tree with ordered freq itemset\n",
    "    return retTree, headerTable #return tree and header table"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "updateTree() grow the Fp-tree with an itemset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def updateTree(items, inTree, headerTable, count):\n",
    "    if items[0] in inTree.children:#check if orderedItems[0] in retTree.children\n",
    "        inTree.children[items[0]].inc(count) #incrament count\n",
    "    else:   #add items[0] to inTree.children\n",
    "        inTree.children[items[0]] = treeNode(items[0], count, inTree)\n",
    "        if headerTable[items[0]][1] == None: #update header table \n",
    "            headerTable[items[0]][1] = inTree.children[items[0]]\n",
    "        else:\n",
    "            updateHeader(headerTable[items[0]][1], inTree.children[items[0]])\n",
    "    if len(items) > 1:#call updateTree() with remaining ordered items\n",
    "        updateTree(items[1::], inTree.children[items[0]], headerTable, count)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "updateHeader() makes sure the node links points to every intance of the this item on the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def updateHeader(nodeToTest, targetNode):   #this version does not use recursion\n",
    "    while (nodeToTest.nodeLink != None):    #Do not use recursion to traverse a linked list!\n",
    "        nodeToTest = nodeToTest.nodeLink\n",
    "    nodeToTest.nodeLink = targetNode"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The createTree() function doesn’t take the input data as lists. It expects a dictionary with the itemsets as the dictionary keys and the frequency as the value. A createInitSet() function does this conversion for you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createInitSet(dataSet):\n",
    "    retDict = {}\n",
    "    for trans in dataSet:\n",
    "        retDict[frozenset(trans)] = 1\n",
    "    return retDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{frozenset({'Albama', 'WIRELESS'}): 1,\n",
       " frozenset({'CB-WIRELINE', 'Newyork'}): 1,\n",
       " frozenset({'CB-WIRELINE', 'Ohio'}): 1,\n",
       " frozenset({'Newyork', 'WIRELESS'}): 1,\n",
       " frozenset({'Penselvaniya', 'WIRELESS'}): 1,\n",
       " frozenset({'Albama', 'Unified (Uverse + Wireless + DTV)'}): 1,\n",
       " frozenset({'CB-WIRELINE', 'Penselvaniya'}): 1,\n",
       " frozenset({'California', 'WIRELESS'}): 1,\n",
       " frozenset({'CB-U-VERSE', 'Texas'}): 1,\n",
       " frozenset({'Newyork', 'Unified (Uverse + Wireless + DTV)'}): 1,\n",
       " frozenset({'CB-WIRELINE', 'Missouri'}): 1,\n",
       " frozenset({'California', 'Unified (Uverse + Wireless + DTV)'}): 1,\n",
       " frozenset({'Indiana', 'Unified (Uverse + Wireless + DTV)'}): 1,\n",
       " frozenset({'Albama', 'CB-U-VERSE'}): 1,\n",
       " frozenset({'Ohio', 'WIRELESS'}): 1,\n",
       " frozenset({'Texas', 'WIRELESS'}): 1,\n",
       " frozenset({'CB-U-VERSE', 'Newyork'}): 1}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initSet = createInitSet(a)\n",
    "initSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('  ', 'Null Set', ' ', 1)\n",
      "('    ', 'Unified (Uverse + Wireless + DTV)', ' ', 3)\n",
      "('      ', 'Albama', ' ', 1)\n",
      "('    ', 'Newyork', ' ', 3)\n",
      "('      ', 'CB-WIRELINE', ' ', 1)\n",
      "('      ', 'Unified (Uverse + Wireless + DTV)', ' ', 1)\n",
      "('      ', 'CB-U-VERSE', ' ', 1)\n",
      "('    ', 'CB-U-VERSE', ' ', 1)\n",
      "('    ', 'WIRELESS', ' ', 6)\n",
      "('      ', 'Newyork', ' ', 1)\n",
      "('      ', 'Albama', ' ', 1)\n",
      "('    ', 'CB-WIRELINE', ' ', 3)\n",
      "('    ', 'Albama', ' ', 1)\n",
      "('      ', 'CB-U-VERSE', ' ', 1)\n"
     ]
    }
   ],
   "source": [
    "myFPtree, myHeaderTab = createTree(initSet, 3)\n",
    "myFPtree.disp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mining frequent items from an FP-tree"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "There are three basic steps to extract the frequent itemsets from the FP-tree:\n",
    "\n",
    "1 Get conditional pattern bases from the FP-tree.\n",
    "\n",
    "2 From the conditional pattern base, construct a conditional FP-tree.\n",
    "\n",
    "3 Recursively repeat steps 1 and 2 on until the tree contains a single item.\n",
    "\n",
    "The conditional pattern base is a collection of paths that end with the item you’re looking for. Each of those paths is a prefix path. In short, a prefix path is anything on the tree between the item you’re looking for and the tree root.\n",
    "\n",
    "ascendTree(), which ascends the tree, collecting the names of items it encounters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ascendTree(leafNode, prefixPath): #ascends from leaf node to root\n",
    "    if leafNode.parent != None:\n",
    "        prefixPath.append(leafNode.name)\n",
    "        ascendTree(leafNode.parent, prefixPath)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The findPrefixPath() function iterates through the linked list until it hits the end. For each item it encounters, it calls ascendTree().\n",
    "\n",
    "This list is returned and added to the conditional pattern base dictionary called condPats.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findPrefixPath(basePat, treeNode): #treeNode comes from header table\n",
    "    condPats = {}\n",
    "    while treeNode != None:\n",
    "        prefixPath = []\n",
    "        ascendTree(treeNode, prefixPath)\n",
    "        if len(prefixPath) > 1: \n",
    "            condPats[frozenset(prefixPath[1:])] = treeNode.count\n",
    "        treeNode = treeNode.nodeLink\n",
    "    return condPats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{frozenset({'WIRELESS'}): 1}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findPrefixPath('Newyork', myHeaderTab['Newyork'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{frozenset({'Unified (Uverse + Wireless + DTV)'}): 1,\n",
       " frozenset({'WIRELESS'}): 1}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findPrefixPath('Albama', myHeaderTab['Albama'][1])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This results clearly explains which plan typw to be implemented in which region of he united states."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Citation:\n",
    "\n",
    "[1].vaish, piush. “Apriori Algorithm (Python 3.0).” A Data Analyst, Piush.vaish, 7 Aug. 2016, adataanalyst.com/machine-learning/apriori-algorithm-python-3-0/."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
